---
default:
  image: docker:20.10.16
  id_tokens:
    VAULT_JWT_TOKEN:
      aud: https://stg.vault.nvidia.com



stages:
  - code_format
  - build
  - test
  - jet
  - deploy

variables:
  # docker build options
  DOCKER_HOST: tcp://docker:2376
  DOCKER_CERT_PATH: "$DOCKER_TLS_CERTDIR/client"
  DOCKER_TLS_VERIFY: 1
  DOCKER_TLS_CERTDIR: "/certs"
  BUILDKIT_PROGRESS: plain
  # image repositories
  NGC_REPO_NAME: "nvcr.io/nvidian/cvai_bnmo_trng/bionemo"
  GITLAB_REPO_NAME: "$CI_REGISTRY_IMAGE"
  IMAGE_REPO_NAME:
    value: "$CI_REGISTRY_IMAGE"
    options:
      - "$CI_REGISTRY_IMAGE"
      - "$NGC_REPO_NAME"
    description: "Allows to control whether NGC or Gitlab registry is used."
  # image tags, or used therein
  PIPELINE_TAG: "pipeline-${CI_PIPELINE_ID}"
  IMAGE_TAG: "${CI_COMMIT_SHA}"
  SUFFIX_DEV: "-devel"
  SUFFIX_DOCS: "-docs"
  SUFFIX_QA: "-qa"
  DATE: "${CI_PIPELINE_CREATED_AT}"
  # fully-qualified image names
  IMAGE_NAME: "${IMAGE_REPO_NAME}:${IMAGE_TAG}"
  CACHE_TAG: "nemo123-20240702"
  IMAGE_CACHE: "${IMAGE_REPO_NAME}:cache--${CACHE_TAG}"
  NEMO_NIGHTLY_IMAGE: "nvcr.io/nvidian/nemo-nightly:latest-nightly-main"
  NGC_CLI_FORMAT_TYPE: ascii
  NGC_CLI_ORG: nvidian
  # TODO(dorotat): change to cvai_bnmo_trng when we move data and checkpoints
  NGC_CLI_TEAM: clara-lifesciences
  # JET variables
  JET_WORKLOAD_FOLDER: "training-inference-unit-tests"
  JET_WORKLOADS_DIR: "internal/jet/workloads/$JET_WORKLOAD_FOLDER"
  ### variables excluding stages of the CI pipeline
  EXCLUDE_DOCKER_IMAGE_BUILD: "false"
  EXCLUDE_DOCS_BUILD: "false"
  EXCLUDE_PYTEST: "false"
  EXCLUDE_JET: "false"
  EXCLUDE_DEPLOY: "true"
  ### variables allowed to be modified when creating pipelines in web Gitlab GUI via Build -> Pipelines -> Run pipeline button
  ### ie when $CI_PIPELINE_SOURCE == "web"
  PYTEST:
    value: "true"
    options:
      - "false"
      - "true"
    description: "a flag that determines whether to run pytest stages. Set to 'true' by default."
  JET:
    value: "true"
    options:
      - "false"
      - "true"
    description: "a flag that determines whether to run tests in JET. Set to 'true' by default."
  NIGHTLY:
    value: "false"
    options:
      - "false"
      - "true"
    description: "a flag that determines whether to use nightly NeMo docker image as base. Set to 'false' by default."
  JET_CONV_TEST:
    value: "false"
    options:
      - "false"
      - "true"
    description: "A flag that determines whether to run partial convergence tests in CI. Set to 'false' by default."
  JET_MODEL_NAME:
    value: "all"
    options:
      - "all"
      - "OpenFold"
      - "ESM2"
      - "ESM1"
      - "ProtT5"
      - "Geneformer"
      - "DNABERT"
      - "MegaMolBART"
      - "MolMIM"
      - "DiffDock"
    description: "A flag that specifies the model for which the JET pipeline should run. Defaults to all models."
  WANDB_PROJECT_SUFFIX:
    value: ""
    description: "A variable that overrides the default suffix in the wandb project name during the jet-configure stage,
    used for logging training curves in convergence tests. When not set, the suffix is set to the branch name.
    The wandb project name is constructed as ${WANDB_PROJECT_NAME_BASE}--${WANDB_PROJECT_SUFFIX} and
    must comply with the regex pattern [a-zA-Z0-9-] to ensure valid naming conventions.
    For more information, refer to internal/jet/README.md or the jet-configure stage implementation."
  WANDB_RUN_SUFFIX:
     value: ""
     description: "A variable that prepends suffix in the wandb run name during the jet-configure stage, used for logging training curves in convergence tests.
     By default, the wandb run name is set to ${CI_PIPELINE_CREATED_AT}_${CI_COMMIT_SHORT_SHA}_${CI_PIPELINE_ID}. For further details, please refer to the WANDB_PROJECT_SUFFIX description"
  QA_DOCKER_DEPLOY:
    value: "false"
    options:
      - "false"
      - "true"
    description: "a flag that determines whether to built & push a docker image for QA. Set to 'false' by default. Remark that only the docker image build and deploy is executed during this pipeline
    resulting in images being pushed to both GitLab and NGC repositories, each tagged with the suffix '${CI_COMMIT_BRANCH}--${DATE_YMD}--${CI_COMMIT_SHA}-qa'"

# TODO(dorotat) solution with SKIP_CI flag is error-prone and should be replaced with better logic!!!!
workflow:
  rules:
    - if: $CI_COMMIT_BRANCH != "dev" && $QA_DOCKER_DEPLOY == "true"
      when: never
    - if: $NIGHTLY == "true" && $QA_DOCKER_DEPLOY == "true"
      when: never
    ## NOTE: QA docker image can be build (if no image on current dev) & deployed to Gitlab/NGC using CI only on dev branch.
    ## It can be built using Run pipeline page (https://gitlab-master.nvidia.com/clara-discovery/bionemo/-/pipelines)
    ## by clicking Run pipeline button and setting QA_DOCKER_DEPLOY=true
    ## Only docker build-bionemo-image stage and qa-deploy are executed. Pipeline with NIGHTLY=true cannot be executed.
    - if: $CI_COMMIT_BRANCH == "dev" && $CI_PIPELINE_SOURCE == "web" &&  $QA_DOCKER_DEPLOY == "true"
      variables:
        EXCLUDE_DOCS_BUILD: "true"
        EXCLUDE_PYTEST: "true"
        EXCLUDE_JET: "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_LABELS =~ /SKIP_CI/
      variables:
        EXCLUDE_DOCKER_IMAGE_BUILD: "true"
        EXCLUDE_DOCS_BUILD: "true"
        EXCLUDE_PYTEST: "true"
        EXCLUDE_JET: "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_LABELS =~ /PYTEST_NOT_REQUIRED/ && $CI_MERGE_REQUEST_LABELS =~ /JET_NOT_REQUIRED/
      variables:
        EXCLUDE_PYTEST: "true"
        EXCLUDE_JET: "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_LABELS =~ /PYTEST_NOT_REQUIRED/
      variables:
        EXCLUDE_PYTEST: "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_LABELS =~ /JET_NOT_REQUIRED/
      variables:
        EXCLUDE_JET: "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    ## NOTE: Convergence test are run using JET via CI. They can be triggered from any branch but only from the Run pipeline page
    ## (https://gitlab-master.nvidia.com/clara-discovery/bionemo/-/pipelines) by clicking Run pipeline button and setting JET_CONV_TEST=true
    ## Only docker build-bionemo-image and jet stage using training definitions from JET_WORKLOAD_FOLDER is executed (docs build and pytest stages is disabled)
    ## TODO(dorotat) Temporary disable ems2 pretrain for conv tests. enable again after ESM2 refactor is done, mid June 2024
    - if: ($CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "schedule") &&  $JET_CONV_TEST == "true"
      variables:
        EXCLUDE_DOCS_BUILD: "true"
        EXCLUDE_PYTEST: "true"
        JET_WORKLOAD_FOLDER: "partial-conv-trainings"
    - if: ($CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "schedule") && $PYTEST != "true" && $JET == "true"
      variables:
        EXCLUDE_PYTEST: "true"
        EXCLUDE_DOCS_BUILD: "true"
    - if: ($CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "schedule") &&  $PYTEST == "true" && $JET != "true"
      variables:
        EXCLUDE_JET: "true"
    - if: ($CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "schedule") &&  $PYTEST != "true" && $JET != "true"
      variables:
        EXCLUDE_PYTEST: "true"
        EXCLUDE_DOCS_BUILD: "true"
        EXCLUDE_JET: "true"
    - if: ($CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "schedule") &&  $PYTEST == "true" && $JET == "true"
    - if: $CI_COMMIT_BRANCH == "dev" && $CI_PIPELINE_SOURCE == "push"
      variables:
        EXCLUDE_DEPLOY: "false"
# Note: We need to use this docker version `docker:26.0.2-dind` or higher for buildx inline caching.
.docker-setup:
  services:
    - name: docker:26.0.2-dind
      command: ["--mtu=1372"]
  tags:
    - dind
  before_script:
    - until docker info; do sleep 1; done
    - mkdir -p $HOME/.docker
    # Prodsec hosts a pull-through cache to speed up builds in kamino cluster. The following config
    # makes buildkit aware of this registry.
    - |
      cat > buildkit.toml <<'EOF'
      debug = false
      EOF
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker login -u '$oauthtoken' -p $NGC_CLI_API_KEY nvcr.io
    - docker context create kamino-context
    - docker buildx create
        --config buildkit.toml
        --driver docker-container
        --use
        --name kamino
        --bootstrap
        --use --buildkitd-flags '--allow-insecure-entitlement network.host'
        kamino-context
    - docker buildx inspect

code_format:
 image: nvcr.io/nvidian/cvai_bnmo_trng/bionemo-linter:latest
 stage: code_format
 rules:
   - if: $JET_CONV_TEST == "true"
     when: never
   - when: always
 tags:
  - generic
 script:
   - pre-commit run --all-files --show-diff-on-failure

license_check:
 image: python:3.10.13-slim
 stage: code_format
 rules:
   - if: $JET_CONV_TEST == "true"
     when: never
   - when: always
 tags:
  - generic
 script:
   - INFRA_BIONEMO_DEP=$(cat setup/requirements-dev.txt | grep "infra-bionemo==")
   - pip install --index-url "https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab-master.nvidia.com/api/v4/projects/118589/packages/pypi/simple" "${INFRA_BIONEMO_DEP}"
   # the bionemo codebase requires the default proprietary license
   - license-check -c setup.py -c bionemo -c tests -c examples -c internal -c hydra_plugins -c fw2nim_examples -c download_artifacts.py -c docs

build-bionemo-image:
  extends:
    - .docker-setup
  stage: build
  rules:
    - if: $EXCLUDE_DOCKER_IMAGE_BUILD == "true"
      when: never
    - when: on_success
  script:
    - df -h
    - if [[ $NIGHTLY = true ]]; then
      base="--build-arg BASE_IMAGE=$NEMO_NIGHTLY_IMAGE";
      else
      base="";
      fi

    # or maybe we built an image for the previous commit that we can use as a layer cache
    # TODO [mgreaves] There's no `git` in DIND :( Odd though -- how does it checkout the code!?
    #    - >
    #      for i in $(seq 1 10); do
    #        docker pull "${IMAGE_REPO_NAME}:$(git rev-parse HEAD~${i})" || true
    #      done
    # TODO [mgreaves] This had --no-cache on it before. Why would we want this?

    # Build cache reference images like this:
    # docker buildx build --cache-to type=inline  -t <your-image-name>  -f Dockerfile .
    # If you build using `bash launch.sh build` this will be done automatically.
    - DATE_YMD="$(echo ${DATE} | cut -f1 -d'T')"
    - TAG_DATE_SHORT_COMMIT="${CI_COMMIT_SHORT_SHA}--${DATE_YMD}"
    - TAG_MR="mr--${CI_MERGE_REQUEST_IID}--${TAG_DATE_SHORT_COMMIT}"
    - if [[ "${CI_MERGE_REQUEST_IID}" != "" ]]; then
        TAG_MR_IMAGE_NAME="${IMAGE_REPO_NAME}:${TAG_MR}"
        TAG_MR_BUILD_STRING="-t ${TAG_MR_IMAGE_NAME}";
        echo "MR docker tag:${TAG_MR_BUILD_STRING}";
      else
        TAG_MR_IMAGE_NAME="";
        TAG_MR_BUILD_STRING="";
      fi
    - BUILD_START=$(date +%s)
    - docker buildx version
    - set -x
    - docker buildx build
      --progress plain
      --network host ${base}
      --label com.nvidia.bionemo.short_git_sha=${CI_COMMIT_SHORT_SHA}
      --label com.nvidia.bionemo.git_sha=${CI_COMMIT_SHA}
      --label com.nvidia.bionemo.created_at=${DATE}
      --label com.nvidia.bionemo.branch=${CI_COMMIT_BRANCH}
      --label com.nvidia.bionemo.pipeline_id=${CI_PIPELINE_ID}
      --label com.nvidia.bionemo.merge_request_id=${CI_MERGE_REQUEST_IID}
      --secret id=GITLAB_TOKEN,env=CI_JOB_TOKEN
      --cache-from="${IMAGE_NAME}"
      --cache-from="${IMAGE_CACHE}"
      --cache-to=type=registry,mode=min,ref="${IMAGE_CACHE}"
      -t "${IMAGE_NAME}"
      -t "${IMAGE_REPO_NAME}:${CI_COMMIT_SHORT_SHA}"
      -t "${IMAGE_REPO_NAME}:${PIPELINE_TAG}"
      -t "${IMAGE_REPO_NAME}:${TAG_DATE_SHORT_COMMIT}"
      ${TAG_MR_BUILD_STRING}
      --push
      -f setup/Dockerfile .
    - set +x
    - BUILD_END=$(date +%s)
    - ELAPSED=$(( BUILD_END - BUILD_START ))
    - echo "container build time using cached ${IMAGE_CACHE}" $ELAPSED
    - df -h
    # tag with short commit too
    # Re-tag with prior pipeline ID format for backwards compatability
    # Also tag this image with a format that uses the date of creation:
    #       YYYY-MM-DD--CCCCCCCC
    # Where 'C..C' are the first 8 characters of the commit

    # For merge request branches only, also tag the image with the merge request number:
    #       mr--MMMM--YYYY-MM-DD--CCCCCCCC
    # Where 'M..M' is the merge request number. Note it is variable-sized.


    #
    # FIXME [mgreaves] See note in internal/Dockerfile-devel about this (it is commented as another 'FIXME').
    #                  tl;dr Secuirty leak: passing in CI_JOB_TOKEN as a build-arg persists its value in the image!
    #
    # To fix, we'll need something like:
    #
    # - TPL_REPO=https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab-master.nvidia.com/dl/gwe/torch_performance_linter
    # - docker build
    #   --network host --no-cache
    #   --build-arg BIONEMO_IMAGE="$PIPELINE_TAG"
    #   --secret id=TPL_REPO,env=TPL_REPO
    #   -t ${IMAGE_NAME}${SUFFIX_DEV} -f internal/Dockerfile-devel .
    #
    # As in, ensure that the CI_JOB_TOKEN makes it way via --secret, not --build-arg.
    #
    # TODO [mgreaves] This had --no-cache on it before. Why would we want this?
    - if [[ "${CI_MERGE_REQUEST_IID}" != "" ]]; then
        TAG_MR_IMAGE_NAME="${IMAGE_REPO_NAME}:${TAG_MR}${SUFFIX_DEV}";
        TAG_MR_BUILD_STRING="-t ${TAG_MR_IMAGE_NAME}";
        echo "MR docker tag:${TAG_MR_BUILD_STRING}";
      else
        TAG_MR_IMAGE_NAME="";
        TAG_MR_BUILD_STRING="";
      fi
    - set -x
    - docker buildx build
        --progress plain
        --network host
        --build-arg BIONEMO_IMAGE="$IMAGE_NAME"
        --build-arg TPL_REPO=https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab-master.nvidia.com/dl/gwe/torch_performance_linter
        --label com.nvidia.bionemo.short_git_sha=${CI_COMMIT_SHORT_SHA}
        --label com.nvidia.bionemo.git_sha=${CI_COMMIT_SHA}
        --label com.nvidia.bionemo.created_at=${DATE}
        --label com.nvidia.bionemo.branch=${CI_COMMIT_BRANCH}
        --label com.nvidia.bionemo.pipeline_id=${CI_PIPELINE_ID}
        --label com.nvidia.bionemo.merge_request_id=${CI_MERGE_REQUEST_IID}
        --cache-from="${IMAGE_NAME}"
        --cache-from="${IMAGE_NAME}${SUFFIX_DEV}-cache"
        --cache-to=type=registry,mode=min,ref="${IMAGE_NAME}${SUFFIX_DEV}-cache"
        -t "${IMAGE_NAME}${SUFFIX_DEV}"
        -t "${IMAGE_REPO_NAME}:${CI_COMMIT_SHORT_SHA}${SUFFIX_DEV}"
        -t "${IMAGE_REPO_NAME}:${PIPELINE_TAG}${SUFFIX_DEV}"
        -t "${IMAGE_REPO_NAME}:${TAG_DATE_SHORT_COMMIT}${SUFFIX_DEV}"
        ${TAG_MR_BUILD_STRING}
        --push
        -f internal/Dockerfile-devel .
    - set +x
    - df -h

build-docs-image:
  extends:
    - .docker-setup
  rules:
    - if: $EXCLUDE_DOCS_BUILD == "true"
      when: never
    - when: on_success
  stage: build
  script:
    - if [[ $NIGHTLY = true ]]; then
      base="--build-arg BASE_IMAGE=$NEMO_NIGHTLY_IMAGE";
      else
      base="";
      fi
    - cd docs/
    # CANNOT use date command -- busybox doesn't support --iso-8601
    # - DATE=$(date --iso-8601=seconds -u)
    # Good thing we have CI_PIPELINE_CREATED_AT !
    - DATE="${CI_PIPELINE_CREATED_AT}"
    - TAG_DATE="$(echo ${DATE} | cut -f1 -d'T')"
    # maybe we built this image on a previous pipeline run -- if so, we don't need to remake it!
    - docker pull ${IMAGE_NAME}${SUFFIX_DOCS} || true
    # or maybe we built an image for the previous commit(s) that we can use as a layer cache
    # TODO [mgreaves] There's no `git` in DIND :( Odd though -- how does it checkout the code!?
    #    - >
    #      for i in $(seq 1 10); do
    #        docker pull "${IMAGE_REPO_NAME}:$(git rev-parse HEAD~${i})${SUFFIX_DOCS}" || true
    #      done
    # TODO [mgreaves] This had --no-cache on it before. Why would we want this?
    - docker build
      --network host ${base}
      --label com.nvidia.bionemo.short_git_sha=${CI_COMMIT_SHORT_SHA}
      --label com.nvidia.bionemo.git_sha=${CI_COMMIT_SHA}
      --label com.nvidia.bionemo.created_at=${DATE}
      --label com.nvidia.bionemo.branch=${CI_COMMIT_BRANCH}
      --label com.nvidia.bionemo.pipeline_id=${CI_PIPELINE_ID}
      --label com.nvidia.bionemo.merge_request_id=${CI_MERGE_REQUEST_IID}
      -t "${IMAGE_NAME}${SUFFIX_DOCS}"
      -f Dockerfile.docs .
    - docker push "${IMAGE_NAME}${SUFFIX_DOCS}"
# Note: It is tempting to build the docs in the same job as build-docs-image, i.e. have a
# `docker run ... sphinx-build ...` command here, however getting the output of this build
# is non-trivial. It is non-trivial to mount volumes to docker commands when DIND is used in
# gitlab-ci, therefore we split the docs image build and docs build into separate jobs,
# where the latter doesn't require DIND.

build-docs:
  image:
    name: "${IMAGE_NAME}${SUFFIX_DOCS}"
    entrypoint: [ "" ]
  stage: build
  needs: [build-docs-image]
  tags:
    - generic
  variables:
    GIT_STRATEGY: none
    GIT_CHECKOUT: "false"
  rules:
    - if: $EXCLUDE_DOCS_BUILD == "true"
      when: never
    - when: on_success
  script:
    # Build the docs, store as artifact in ${CI_PROJECT_DIR = /builds/clara-discovery/bionemo}.
    - mkdir -p /builds/clara-discovery/bionemo/docs_build
    - cd /docs
    - sphinx-build bionemo /builds/clara-discovery/bionemo/docs_build/html
  artifacts:
      paths:
        - docs_build
      expire_in: 1 week

.common_pytest_no_gpu_before_script: &common_no_gpu_before_script
  before_script:
    - df -Thl
    - pwd
    - export BIONEMO_HOME="${BIONEMO_HOME:-/workspace/bionemo}"
    - echo "Copying $BIONEMO_HOME to /builds/bionemo"
    - ls $BIONEMO_HOME
    - mkdir -p /builds/bionemo/
    - cp -av "${BIONEMO_HOME}" /builds/
    - rm -rf "${BIONEMO_HOME}"
    - ln -s /builds/bionemo "${BIONEMO_HOME}"
    - export BIONEMO_HOME="/builds/bionemo"
    - echo "Updated BIONEMO_HOME to $BIONEMO_HOME"
    - echo "Current storage drive utilization:"
    - ls -lts /
    - df -Thl
    - cd "${BIONEMO_HOME}"
    - ls -ltr
    - pwd

.common_pytest_before_script: &common_before_script
  before_script:
    - nvidia-smi
    - df -Thl
    - pwd
    - echo $BIONEMO_HOME
    - ls $BIONEMO_HOME
    - mkdir -p /builds/bionemo/
    - cp -av $BIONEMO_HOME /builds/
    - rm /workspace/bionemo -rf
    - ln -s /builds/bionemo /workspace/bionemo
    - export BIONEMO_HOME=/builds/bionemo
    - echo $BIONEMO_HOME
    - cd $BIONEMO_HOME
    - ls -ltr
    - ls -lts /
    - df -Thl
    # maybe possible to "inherit" another?
    # https://stackoverflow.com/a/76372616/362021
    # - !reference [".common_pytest_no_gpu_before_script", "before_script"]

pytest:
  extends:
    - .common_pytest_before_script
  image:
    name: "${IMAGE_NAME}${SUFFIX_DEV}"
    entrypoint: [ "" ]
  stage: test
  needs: [build-bionemo-image]
  rules:
    - if: $EXCLUDE_PYTEST == "true"
      when: never
    - when: on_success
  tags:
    - gpu
  variables:
    GIT_STRATEGY: none
    GIT_CHECKOUT: "false"
  script:
    # TODO(trvachov): This install the NGC CLI, but this should be removed once all of our tests stop relying on data from NGC.
    # install_thirdy_party.sh: libaries needed for openfold, that cannot be distributed in the container
    - wget --content-disposition https://api.ngc.nvidia.com/v2/resources/nvidia/ngc-apps/ngc_cli/versions/3.40.0/files/ngccli_linux.zip -O /tmp/ngccli_linux.zip && unzip /tmp/ngccli_linux.zip -d /tmp/ && export PATH=$PATH:/tmp/ngc-cli
    - export NGC_CLI_ORG NGC_CLI_TEAM NGC_CLI_FORMAT_TYPE NGC_CLI_API_KEY
    - export AWS_ENDPOINT_URL=https://pbss.s8k.io
    - export AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY
    - export MODEL_PATH=${BIONEMO_HOME}/models
    - bash ./examples/protein/openfold/scripts/install_third_party.sh
    - python download_artifacts.py --models openfold_finetuning_inhouse esm2nv_3b esm2nv_8m_lora esm2nv_8m_untrained esm2nv_650m diffdock_confidence diffdock_score equidock_db5 equidock_dips megamolbart molmim_70m_24_3 prott5nv esm1nv dnabert geneformer dsmbind --source pbss --model_dir $MODEL_PATH  --data all --data_dir $BIONEMO_HOME --verbose
    - unzip examples/tests/test_data/uniref202104_esm2_qc_test200_val200.zip -d examples/tests/test_data/
    - bash ./examples/singlecell/geneformer/scripts/download_sample_data.sh -data_path $BIONEMO_HOME/examples/tests/test_data
    - python ./examples/singlecell/geneformer/scripts/get_pt_neighbors_data.py
    - ls examples/tests/test_data/uniref202104_esm2_qc_test200_val200
    - rm -rf ./.pytest_cache/
    - mkdir -p ${CI_PROJECT_DIR}/heatmaps
    - pytest -m "not internal and not needs_fork and not needs_80gb_memory_gpu" -vv --durations=0 --cov=bionemo --cov-report term --cov-report xml:coverage.xml -k "not test_model_training" | tee pytest_report.log
    # Compute test coverage with higher precision, i.e. up to 2 decimal digits. (In the logs, we'll have 8 decimal digits.)
    # From "TOTAL ${TOTAL STATEMENTS} ${NON-COVERED STATEMENTS} ${COVERAGE PERCENT}", compute (${TOTAL STATEMENTS} - ${NON-COVERED STATEMENTS}) / ${TOTAL STATEMENTS}.
    - cat pytest_report.log | grep -Eo "TOTAL\s+[0-9]+\s+[0-9]+\s+[0-9]+%" | python -c 'import sys; lines=sys.stdin.readline(); x = lines.split(); n = int(x[1]) - int(x[2]); print(f"BIONEMO TEST COVERAGE = {100 * n / int(x[1]):.8f}%")'
    - cp -rv ${BIONEMO_HOME}/tests/data/esm2_golden_values/heatmaps ${CI_PROJECT_DIR}/heatmaps
    - cp ${BIONEMO_HOME}/coverage.xml ${CI_PROJECT_DIR}
    - df -Thl
    - if [ ! -e "${CI_PROJECT_DIR}/coverage.xml" ]; then echo "${CI_PROJECT_DIR}/coverage.xml does not exist. Failing..."; exit 1; fi
  coverage: '/BIONEMO TEST COVERAGE = ([0-9]+\.*[0-9]*%)/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        # Relative path in ${CI_PROJECT_DIR}...
        path: coverage.xml
    paths:
      - heatmaps

pytest-nim-examples:
  extends:
    - .common_pytest_no_gpu_before_script
  image:
    # requires -dev image because fw2nim_examples/ is *not* included in release image
    name: "${IMAGE_NAME}${SUFFIX_DEV}"
    entrypoint: [ "" ]
  stage: test
  needs: [build-bionemo-image]
  rules:
    - if: $EXCLUDE_PYTEST == "true"
      when: never
    - when: on_success
  tags:
    - generic
  variables:
    GIT_STRATEGY: none
    GIT_CHECKOUT: "false"
  script:
    # test each NIM example
    - pushd fw2nim_examples/molmim
    - pip install --no-deps -e .
    - pytest -v .
    - popd



pytest-fork:
  extends:
    - .common_pytest_before_script
  image:
    name: "${IMAGE_NAME}${SUFFIX_DEV}"
    entrypoint: [ "" ]
  stage: test
  needs: [build-bionemo-image]
  rules:
    - if: $EXCLUDE_PYTEST == "true"
      when: never
    - when: on_success
  tags:
    - gpu
  variables:
    GIT_STRATEGY: none
    GIT_CHECKOUT: "false"
  script:
    - export NGC_CLI_ORG NGC_CLI_TEAM NGC_CLI_FORMAT_TYPE NGC_CLI_API_KEY
    - export AWS_ENDPOINT_URL=https://pbss.s8k.io
    - export AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY
    - export MODEL_PATH=${BIONEMO_HOME}/models
    - python download_artifacts.py --models openfold_finetuning_inhouse esm2nv_3b esm2nv_650m diffdock_confidence diffdock_score equidock_db5 equidock_dips megamolbart prott5nv molmim_70m_24_3 geneformer esm1nv dnabert enformer_finetuned16 enformer_finetuned32 dsmbind --source pbss --model_dir $MODEL_PATH  --data all  --data_dir $BIONEMO_HOME --verbose
    - unzip examples/tests/test_data/uniref202104_esm2_qc_test200_val200.zip -d examples/tests/test_data/
    # unit tests which need to be run in a separate process
    - bash internal/run_pytest_fork.sh
    - df -Thl


pytest-internal:
  extends:
    - .common_pytest_before_script
  image:
    name: "${IMAGE_NAME}${SUFFIX_DEV}"
    entrypoint: [ "" ]
  stage: test
  needs: [build-bionemo-image]
  allow_failure: false
  rules:
    - if: $EXCLUDE_PYTEST == "true"
      when: never
    - when: on_success
  tags:
    - gpu
  variables:
    GIT_STRATEGY: none
    GIT_CHECKOUT: "false"
  script:
    - export NGC_CLI_ORG NGC_CLI_TEAM NGC_CLI_FORMAT_TYPE NGC_CLI_API_KEY
    - export AWS_ENDPOINT_URL=https://pbss.s8k.io
    - export AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY
    - export MODEL_PATH=${BIONEMO_HOME}/models
    - python download_artifacts.py --models esm2_650m_huggingface esm2_3b_huggingface --source pbss --model_dir $MODEL_PATH --verbose
    - echo "Checking test data contents..."
    - rm -rf ./.pytest_cache/
    - pytest -m "internal" -v --durations=0 --cov=bionemo --cov-report term --cov-report xml:coverage.xml -k "not test_model_training"
    - df -Thl


.jet-configure:
  stage: jet
  tags:
    - generic
  needs:
    - job: build-bionemo-image
      optional: true
    - job: pytest
      optional: true
    - job: pytest-fork
      optional: true
    - job: pytest-internal
      optional: true
  after_script:
    - echo "JET_WORKLOADS_PROJECT=$CI_PROJECT_ID" >> jet.env
    - echo "JET_WORKLOADS_JOB=$CI_JOB_ID" >> jet.env
  artifacts:
    reports:
      dotenv: jet.env



jet-configure:
  extends: [.jet-configure]
  variables:
    JET_WORKLOADS_REF_BASE: "bionemo"
    JET_WORKLOADS_REF: "${JET_WORKLOADS_REF_BASE}/${CI_COMMIT_BRANCH}"
    WANDB_PROJECT_NAME_BASE: "jet--${JET_WORKLOAD_FOLDER}"
    WANDB_RUN_NAME: "${CI_PIPELINE_CREATED_AT}_${CI_COMMIT_SHORT_SHA}_${CI_PIPELINE_ID}"
  artifacts:
    paths:
      - $JET_WORKLOADS_DIR
  rules:
    - if: $EXCLUDE_JET == "true"
      when: never
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $EXCLUDE_JET != "true"
      when: manual
      variables:
        JET_WORKLOADS_REF: "bionemo/merge_request_event"
    - when: on_success
  before_script:
    - apk update && apk add git yq
    - |
      if [[ $CI_PIPELINE_SOURCE == "merge_request_event" ]]; then
        CUSTOM_BRANCH_NAME=$(echo "$CI_MERGE_REQUEST_SOURCE_BRANCH_NAME" | tr "/" "__")
      else
        CUSTOM_BRANCH_NAME=$(echo "$CI_COMMIT_BRANCH" | tr "/" "__")
      fi
    - |
      if [ -z "${WANDB_PROJECT_SUFFIX}" ]; then
        WANDB_PROJECT_SUFFIX="${CUSTOM_BRANCH_NAME}"
      fi
    - export WANDB_PROJECT_NAME="${WANDB_PROJECT_NAME_BASE}--${WANDB_PROJECT_SUFFIX}"
    - |
      if [ -n "${WANDB_RUN_SUFFIX}" ]; then
        WANDB_RUN_NAME="${WANDB_RUN_SUFFIX}--${WANDB_RUN_NAME}"
      fi
    - export WANDB_RUN_NAME
    - echo "WANDB_PROJECT_NAME is set to ${WANDB_PROJECT_NAME}"
    - echo "WANDB_RUN_NAME is set to ${WANDB_RUN_NAME}"
  script:
    - yq e ".spec.source.image = \"${IMAGE_NAME}\"" -i ${JET_WORKLOADS_DIR}/builds/bionemo.yaml
    - 'find "$JET_WORKLOADS_DIR" -type f -name "*.yaml" -print0 | while IFS= read -r -d "" file; do
          echo "File: $file";
          yq e ".labels.workload_ref = \"${JET_WORKLOADS_REF}\"" -i ${file};
          yq e ".labels.bionemo_ci_pipeline_id = \"${CI_PIPELINE_ID}\"" -i ${file};
          yq e ".labels.bionemo_commit_sha = \"${CI_COMMIT_SHORT_SHA}\"" -i ${file};
          yq e ".spec.scope = \"${JET_WORKLOAD_FOLDER}\"" -i ${file};
          if [[ $JET_CONV_TEST = true ]] & [[ $file == *"recipe"* ]]; then
            yq e ".spec.wandb_project_name = \"${WANDB_PROJECT_NAME}\"" -i ${file};
            yq e ".spec.pipeline_label = \"${WANDB_RUN_NAME}\"" -i ${file};
          fi;
          cat ${file};
       done'


.jet-trigger-template:
  stage: jet
  needs: [jet-configure]
  inherit:
    variables: true
  variables:
    JET_WORKLOADS_PROJECT: $JET_WORKLOADS_PROJECT
    JET_WORKLOADS_JOB: $JET_WORKLOADS_JOB
    JET_BUILDS_PLATFORMS: linux/amd64
  trigger:
    project: dl/jet/ci
    branch: bionemo # NOTE: this branch name enables running JET on Draco OCI
    strategy: depend

#### ADDITIONAL RESOURCES ON jet-trigger ####
# jet-trigger stage described in JET docs: https://jet.nvidia.com/docs/execution/ci-cd/downstream-pipelines/
# it uses base_config.yaml for the configuration of bionemo account under: https://gitlab-master.nvidia.com/dl/jet/ci/-/blob/bionemo/base_config.yaml?ref_type=heads
#####
# restarter - restarting jobs which failed due to <ERROR_CODE> listed under retry_on: [<ERROR_CODE>]
# for more info about error codes see https://jet.nvidia.com/docs/logs/status/
####
# deadline - increases the time limit of jobs queueing on SLURM clusters, here dgxa100_dracooci
# default deadline under corresponding section in base_config.yaml: https://gitlab-master.nvidia.com/dl/jet/ci/-/blob/bionemo/base_config.yaml?ref_type=heads#L33
jet-trigger:
  extends: [.jet-trigger-template]
  variables:
    JET_WORKLOADS_FILTER: type == 'recipe'
    JET_CUSTOM_CONFIG: |
      tests:
        allow_failure: true
      retrier:
        enabled: true
        max_retries: 2
        retry_on: ['1.2', '1.2.*', '1.1.1.1']
        waiting_time: 60
        environment: jet-auto-retrier
      launchers:
        dgxa100_dracooci:
          additional_flags:
            deadline: now+42hours
  inherit:
    variables:
      - EXCLUDE_JET
      - JET_MODEL_NAME
      - CI_MERGE_REQUEST_LABELS
  rules:
    - if: $EXCLUDE_JET == "true"
      when: never
    - if: $CI_MERGE_REQUEST_LABELS =~ /OpenFold/ || $JET_MODEL_NAME == "OpenFold"
      variables:
        JET_WORKLOADS_FILTER: type == 'recipe' and spec.model == 'openfold'
    - if: $CI_MERGE_REQUEST_LABELS =~ /ESM2/ || $JET_MODEL_NAME == "ESM2"
      variables:
        JET_WORKLOADS_FILTER: type == 'recipe' and spec.model == 'esm2nv'
    - if: $CI_MERGE_REQUEST_LABELS =~ /ESM1/ || $JET_MODEL_NAME == "ESM1"
      variables:
        JET_WORKLOADS_FILTER: type == 'recipe' and spec.model == 'esm1nv'
    - if: $CI_MERGE_REQUEST_LABELS =~ /ProtT5/ || $JET_MODEL_NAME == "ProtT5"
      variables:
        JET_WORKLOADS_FILTER: type == 'recipe' and spec.model == 'prott5nv'
    - if: $CI_MERGE_REQUEST_LABELS =~ /Geneformer/ || $JET_MODEL_NAME == "Geneformer"
      variables:
        JET_WORKLOADS_FILTER: type == 'recipe' and spec.model == 'geneformer'
    - if: $CI_MERGE_REQUEST_LABELS =~ /DNABERT/ || $JET_MODEL_NAME == "DNABERT"
      variables:
        JET_WORKLOADS_FILTER: type == 'recipe' and spec.model == 'dnabert'
    - if: $CI_MERGE_REQUEST_LABELS =~ /MegaMolBART/ || $JET_MODEL_NAME == "MegaMolBART"
      variables:
        JET_WORKLOADS_FILTER: type == 'recipe' and spec.model == 'megamolbart'
    - if: $CI_MERGE_REQUEST_LABELS =~ /MolMIM/ || $JET_MODEL_NAME == "MolMIM"
      variables:
        JET_WORKLOADS_FILTER: type == 'recipe' and spec.model == 'molmim'
    - if: $CI_MERGE_REQUEST_LABELS =~ /DiffDock/ || $JET_MODEL_NAME == "DiffDock"
      variables:
        JET_WORKLOADS_FILTER: type == 'recipe' and spec.model == 'diffdock'
    - when: on_success


# The jet-test job always runs after the jet-trigger job, regardless of its success or failure.
# This is achieved by setting allow_failure: true for jet-trigger, which marks it as successful even if it fails.
# The jet-test job, configured with when: on_success, then checks the status of jet-trigger and fails if jet-trigger failed.
# The jet-test stage has delayed execution by setting sleep 60 to ensure that jet logs have been uploaded from jet-trigger.
jet-test:
  needs: [jet-trigger]
  rules:
    - if: $EXCLUDE_JET == "true"
      when: never
    - when: on_success
  image:
    name: gitlab-master.nvidia.com:5005/dl/jet/api:latest
    entrypoint: [ "" ]
  tags:
    - generic
  stage: jet
  before_script:
    - sleep 60  # Delay for 1 minute (60 seconds)
    - pip install tqdm
    - export RO_API_TOKEN CI_PROJECT_ID CI_PIPELINE_ID GITLAB_USER_LOGIN
    - jet secrets jwt-login jwt/nvidia/gitlab-master bionemo-ci $VAULT_JWT_TOKEN
  script:
    - echo "CI_PROJECT_ID=${CI_PROJECT_ID}, CI_PIPELINE_ID=${CI_PIPELINE_ID}"
    - bash $CI_PROJECT_DIR/internal/jet/scripts/run_jet_test.sh


# triggering an update of the dashboard for convergence tests when the tests are finished
# Repository with the dashboard deployment: https://gitlab-master.nvidia.com/clara-discovery/dashboards
dashboard-update-trigger:
  stage: jet
  needs: [jet-trigger]
  rules:
    - if: $JET_CONV_TEST == "true" && $CI_COMMIT_BRANCH == "dev"
      when: always
  trigger:
    project: clara-discovery/dashboards
    branch: main
    strategy: depend


qa-deploy:
  stage: deploy
  extends:
    - .docker-setup
  rules:
    - if: $QA_DOCKER_DEPLOY == "true"
  script:
    - docker pull "${IMAGE_NAME}"
    - DATE_YMD="$(echo ${DATE} | cut -f1 -d'T')"
    # QA image tag has format that uses the branch, date of creation & :
    #       BBBB--YYYY-MM-DD--CCCCCCCC-qa
    # Where 'C..C' are the first 8 characters of the commit
    # Where 'B...B' is the branch name. (Note: rules filter out invalid branch names!)
    - IMAGE_TAG_QA="${CI_COMMIT_BRANCH}--${DATE_YMD}--${CI_COMMIT_SHA}${SUFFIX_QA}"
    - IMAGE_NAME_QA="${IMAGE_REPO_NAME}:${IMAGE_TAG_QA}"
    - docker tag "${IMAGE_NAME}" "${IMAGE_NAME_QA}"
    - docker push "${IMAGE_NAME_QA}"
    - docker tag "${IMAGE_NAME}" nvcr.io/nvidian/cvai_bnmo_trng/bionemo:cache-py23.10
    - docker push nvcr.io/nvidian/cvai_bnmo_trng/bionemo:cache-py23.10
    - NGC_IMAGE_NAME_QA="${NGC_REPO_NAME}:${IMAGE_TAG_QA}"
    - docker tag "${IMAGE_NAME}" "${NGC_IMAGE_NAME_QA}"
    - docker push "${NGC_IMAGE_NAME_QA}"


dev-deploy:
  extends:
    - .docker-setup
  stage: deploy
  dependencies: [ ]
  rules:
    - if: $EXCLUDE_DEPLOY == "true"
      when: never
    - when: on_success
  before_script:
    - !reference [ .docker-setup, before_script ]
    - apk update && apk add curl
  script:
    # Get the images that we need to re-tag and publish on other image registries.
    - docker pull "${IMAGE_NAME}"
    - docker pull "${IMAGE_NAME}${SUFFIX_DEV}"
    # NOTE: CANNOT use date command -- busybox doesn't support --iso-8601
    # - DATE=$(date --iso-8601=seconds -u)
    # This is why we use the gitlab CI date env var.
    #
    # Push FW image to NGC
    - docker tag "${IMAGE_NAME}" "${NGC_REPO_NAME}:${IMAGE_TAG}"
    - docker push "${NGC_REPO_NAME}:${IMAGE_TAG}"
    # Also tag this image with a format that uses the branch & date of creation*:
    #       BBBB--YYYY-MM-DD--CCCCCCCC
    # Where 'C..C' are the first 8 characters of the commit
    # Where 'B...B' is the branch name. (Note: rules filter out invalid branch names!)
    # *NOTE: the branch name is included IFF it is "main" or "dev"
    #        otherwise, the first part -- "BBBB---" -- is **NOT** included!
    - DATE_YMD="$(echo ${DATE} | cut -f1 -d'T')"
    - TAG_DATE_SHORT_COMMIT="${CI_COMMIT_SHORT_SHA}--${DATE_YMD}"
    - docker tag "${IMAGE_NAME}" "${NGC_REPO_NAME}:${TAG_DATE_SHORT_COMMIT}"
    - docker push "${NGC_REPO_NAME}:${TAG_DATE_SHORT_COMMIT}"
    # Push -devel image to NGC too
    - docker tag "${IMAGE_NAME}${SUFFIX_DEV}" "${NGC_REPO_NAME}:${CI_COMMIT_SHA}${SUFFIX_DEV}"
    - docker push "${NGC_REPO_NAME}:${CI_COMMIT_SHA}${SUFFIX_DEV}"
    # also, MAYBE tag w/ branch name and push
    - >
      if [[ "${CI_COMMIT_BRANCH}" == "main" || "${CI_COMMIT_BRANCH}" == "dev" ]]; then
        TAG_BRANCH_DATE_SHORT_COMMIT="${CI_COMMIT_BRANCH}--${TAG_DATE_SHORT_COMMIT}"
        # main image
        docker tag "${IMAGE_NAME}" "${NGC_REPO_NAME}:${TAG_BRANCH_DATE_SHORT_COMMIT}"
        docker push "${NGC_REPO_NAME}:${TAG_BRANCH_DATE_SHORT_COMMIT}"
        # -devel image
        docker tag "${IMAGE_NAME}${SUFFIX_DEV}" "${NGC_REPO_NAME}:${TAG_BRANCH_DATE_SHORT_COMMIT}${SUFFIX_DEV}"
        docker push "${NGC_REPO_NAME}:${TAG_BRANCH_DATE_SHORT_COMMIT}${SUFFIX_DEV}"
      fi
