type: recipe
format_version: 1
maintainers: [dorotat]
loggers: [tensorboard, dllogger, extra]
labels:
  origin: bionemo
  workload_ref: ""
  bionemo_ci_pipeline_id: ""
  bionemo_commit_sha: ""
key_segments:
  domain: domain
  config_name: config
  warmup: warmup
  default_overwrites: False
  extra_overwrites: False
  seed: seed
  max_epochs: mepochs
launchers:
  type:slurm:
    ntasks_per_node: '{gpus}'
  name:dgxa100_dracooci:
    mounts:
      /workspace/bionemo/models: /lustre/fsw/portfolios/healthcareeng/projects/healthcareeng_bionemo/jet/models
      /workspace/bionemo/data: /lustre/fsw/portfolios/healthcareeng/projects/healthcareeng_bionemo/jet/data
      /misc_data/npz: /lustre/fsw/portfolios/healthcareeng/users/guoqingz/src/bionemo_code/misc_data/npz
spec:
  build: bionemo
  BIONEMO_HOME: "/workspace/bionemo"
  scope: ""
  platforms: [linux/amd64]
  NGC_CLI_FORMAT_TYPE: ascii
  NGC_CLI_ORG: nvidian
  NGC_CLI_TEAM: clara-lifesciences
  wandb_project_name: ""
  pipeline_label: ""
  warmup: 200
  default_overwrites: "++exp_manager.create_tensorboard_logger=True ++exp_manager.wandb_logger_kwargs.offline=False ++exp_manager.create_wandb_logger=True ++exp_manager.create_checkpoint_callback=False ++exp_manager.resume_if_exists=False"
  extra_overwrites: ""
  script: |-
    cd {BIONEMO_HOME};
    mkdir -p {tensorboard_dir};
    if [ "$SLURM_LOCALID" = "0" ]; then cp /misc_data/npz/.*.npz {BIONEMO_HOME}/bionemo/model/molecule/diffdock/; fi;
    export PYTORCH_CUDA_ALLOC_CONF=backend:cudaMallocAsync;
    export WANDB_API_KEY=$BIONEMO_WANDB_API_KEY;
    model_tag={model}__{variant}__{config_name};
    python examples/{domain}/{model}/{variant}.py --config-name {config_name} \
    trainer.num_nodes={nodes} trainer.devices={gpus} trainer.precision={precision} seed={seed} \
    data.num_workers={num_workers} \
    trainer.max_epochs={max_epochs} model.micro_batch_size={batch_size} \
    data.cache_path={BIONEMO_HOME}/data/diffdock_conv_test_data/data_cache \
    data.split_train={BIONEMO_HOME}/data/diffdock_conv_test_data/splits/train \
    data.split_val={BIONEMO_HOME}/data/diffdock_conv_test_data/splits/val \
    data.split_test={BIONEMO_HOME}/data/diffdock_conv_test_data/splits/test \
    {default_overwrites} {extra_overwrites} \
    ++exp_manager.exp_dir={tensorboard_dir} \
    ++exp_manager.wandb_logger_kwargs.project={wandb_project_name} \
    ++exp_manager.wandb_logger_kwargs.group=${{model_tag}} \
    ++exp_manager.wandb_logger_kwargs.job_type={pipeline_label} \
    ++exp_manager.wandb_logger_kwargs.name={precision}prec_{batch_size}bs_{nodes}node_{gpus}gpu_{max_epochs}e \
    ++create_dllogger_callbacks=True ++create_trainer_metric_callback=True \
    ++dllogger_callbacks_kwargs.use_existing_dllogger=True ++dllogger_callbacks_kwargs.warmup={warmup} \
    ++dllogger_callbacks_kwargs.json_file={dllogger_file} ++trainer_metric_callback_kwargs.log_path={assets_dir} \
    ++logs_dir={logs_dir};
  time_limit: 14400
  artifacts: {}
metrics:
  train_loss_step:
    goal: minimize
    tags: [accuracy]
    key: primary
  train_loss_epoch:
    goal: minimize
    tags: [accuracy]
    key: secondary
  valinf_rmsds_lt2:
    goal: maximize
    tags: [secondary]
    key: tertiary
  valinf_rmsds_lt5:
    goal: maximize
    tags: [accuracy ]
    key: 4th
products:
  - domain: [molecule]
    variant: [train]
    model: [diffdock]
    nodes: [1]
    gpus: [8]
    max_epochs: [ 80 ]
    batch_size: [ 12 ]
    precision: [ 32 ]
    seed: [42, 44, 1234]
    num_workers: [4]
    products:
      - config_name: [train_score]
      - config_name: [train_confidence]
tests_spec:
  - logic_type: static
    logic_spec:
      exit_codes:
        - 0
      baselines:
        # mean -/+ 5 * std
        train_loss_epoch:
          operator: range
          max: 0.644
          min: 0.607
        train_loss_step:
          operator: range
          max: 0.759
          min: 0.45
        valinf_rmsds_lt2:
          operator: range
          max: 0.096
          min: 0.035
        valinf_rmsds_lt5:
          operator: range
          max: 0.377
          min: 0.2
    product_identifier: {'config_name': 'train_score'}
  - logic_type: static
    logic_spec:
      exit_codes:
        - 0
      baselines:
        # mean -/+ 5 * std
        train_loss_epoch:
          operator: range
          max: 0.0966
          min: 0.0624
        train_loss_step:
          operator: range
          max: 0.393
          min: 0
        val_loss:
          operator: range
          max: 0.251
          min: 0.10
    product_identifier: {'config_name': 'train_confidence' }
