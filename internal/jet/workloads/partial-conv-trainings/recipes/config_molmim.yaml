type: recipe
format_version: 1
maintainers: [dorotat]
loggers: [tensorboard, dllogger, extra]
labels:
  origin: bionemo
  workload_ref: ""
  bionemo_ci_pipeline_id: ""
  bionemo_commit_sha: ""
key_segments:
  domain: domain
  config_name: config
  warmup: warmup
  default_overwrites: False
  extra_overwrites: False
  seed: seed
  max_steps: msteps
  dwnstr_task: dwnstrtask
  val_check_interval: valcheck
launchers:
  type:slurm:
    ntasks_per_node: '{gpus}'
  name:dgxa100_dracooci:
    mounts:
      /data : /lustre/fsw/portfolios/healthcareeng/projects/healthcareeng_bionemo/jet/data/ZINC15
spec:
  build: bionemo
  scope: ""
  BIONEMO_HOME: "/workspace/bionemo"
  platforms: [linux/amd64]
  wandb_project_name: ""
  wandb_run_link: ""
  pipeline_label: ""
  warmup: 200
  default_overwrites: "++exp_manager.create_tensorboard_logger=True ++exp_manager.wandb_logger_kwargs.offline=False ++exp_manager.create_wandb_logger=True ++exp_manager.create_checkpoint_callback=False ++exp_manager.resume_if_exists=False"
  extra_overwrites: ""
  script: |-
    cd {BIONEMO_HOME};
    mkdir -p {tensorboard_dir};
    export WANDB_API_KEY=$BIONEMO_WANDB_API_KEY;
    model_tag={model}_{variant}_{config_name}_{dwnstr_task}dwnstr;
    python examples/{domain}/{model}/{variant}.py --config-name {config_name} \
    trainer.num_nodes={nodes} trainer.devices={gpus} trainer.precision={precision} model.micro_batch_size={batch_size} \
    trainer.val_check_interval={val_check_interval} ++model.seed={seed} trainer.max_steps={max_steps} ++model.global_batch_size=null \
    ++exp_manager.exp_dir={tensorboard_dir} ++model.dwnstr_task_validation.enabled={dwnstr_task} \
    ++model.data.index_mapping_dir={BIONEMO_HOME}/data/index_dir/{config_name} \
    {default_overwrites} {extra_overwrites}  \
    ++exp_manager.wandb_logger_kwargs.project={wandb_project_name} \
    ++exp_manager.wandb_logger_kwargs.group=${{model_tag}} \
    ++exp_manager.wandb_logger_kwargs.job_type={pipeline_label} \
    ++exp_manager.wandb_logger_kwargs.name={precision}prec_{batch_size}bs_{nodes}node_{gpus}gpu_{max_steps}s_{val_check_interval}valcheck \
    ++create_dllogger_callbacks=True ++create_trainer_metric_callback=True \
    ++dllogger_callbacks_kwargs.use_existing_dllogger=True ++dllogger_callbacks_kwargs.warmup={warmup} \
    ++dllogger_callbacks_kwargs.json_file={dllogger_file} ++trainer_metric_callback_kwargs.log_path={assets_dir} \
    ++logs_dir={logs_dir};
  time_limit: 12600
  artifacts: {}
metrics:
  reduced_train_tokens_loss:
    goal: minimize
    tags: [accuracy]
    key: primary
  reduced_train_hiddens_mim_loss:
    goal: minimize
    tags: [accuracy]
    key: secondary
  val_percent_invalid:
    goal: minimize
    tags: [accuracy ]
    key: tertiary
  val_character_accuracy:
    goal: minimize
    tags: [ accuracy ]
    key: 4th
  val_loss:
    goal: minimize
    tags: [ accuracy ]
    key: 4th
products:
  - nodes: [2]
    gpus: [8]
    precision: [32]
    products:
      - domain: [molecule]
        dwnstr_task: [False]
        products:
          - variant: [pretrain]
            model: [molmim]
            config_name: [molmim_70m_24_3]
            batch_size: [2048]
            max_steps: [14085]
            seed: [42, 44, 1234]
            val_check_interval: [2500]
tests_spec:
  - logic_type: static
    logic_spec:
      exit_codes:
        - 0
      baselines:
        reduced_train_tokens_loss:
          operator: range
          max: 0.06
          min: 0.0  # sanity check
        reduced_train_hiddens_mim_loss:
          # primary
          operator: range
          max: 0.52
          min: 0.0 # sanity check
        val_percent_invalid:
          # primary
          operator: range
          max: 0.0035
          min: 0.0 # sanity check
        consumed_samples:
          # primary (this should be exact)
          operator: eq
          value: 458752000.0  # bs*gpus_node*nodes*steps=2048*8*2*14085=461537280
        val_character_accuracy:
          # primary
          operator: range
          max: 1.0 # sanity check
          min: 0.97
        val_loss:
          # primary
          operator: range
          max: 0.46
          min: 0.0 # sanity check
        val_molecular_accuracy:
          # primary
          operator: range
          max: 1.0 # sanity check
          min: 0.81
        reduced_train_loss:
          # primary
          operator: range
          max: 0.55
          min: 0.49 # sanity check
        grad_norm:
          # primary
          operator: range
          max: 0.2
          min: 0.0 # sanity check
        reduced_train_hiddens_mim_log_prob_P_z:
          # primary
          operator: geq
          value: -1.09
        val_tokens_loss:
          # primary
          operator: range
          max: 0.067
          min: 0.0 # sanity check
