{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from scipy.sparse import csr_matrix, issparse\n",
    "from scipy.stats import iqr\n",
    "from bionemo.scdl.io.single_cell_memmap_dataset import SingleCellMemMapDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import wraps\n",
    "\n",
    "import subprocess\n",
    "from bionemo.scdl.util.torch_dataloader_utils import collate_sparse_matrix_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disk_size(directory):\n",
    "    result = subprocess.run(['du', '-sb', directory], stdout=subprocess.PIPE, text=True)\n",
    "    size_in_bytes = int(result.stdout.split()[0])\n",
    "    return size_in_bytes\n",
    "def timeit(method):\n",
    "    @wraps(method)\n",
    "    def timed(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = method(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Method {method.__name__} took {end_time - start_time:.4f} seconds\")\n",
    "        return result\n",
    "    return timed\n",
    "\n",
    "def time_all_methods(cls):\n",
    "    for attr_name, attr_value in cls.__dict__.items():\n",
    "        if callable(attr_value):  # Check if the attribute is a method\n",
    "            setattr(cls, attr_name, timeit(attr_value))\n",
    "    return cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_all_methods\n",
    "class AnnDataMetrics:\n",
    "    def __init__(self, adatapath):\n",
    "        self.adatapath = adatapath\n",
    "    def load_backed(self):\n",
    "        self.adata_backed = ad.read_h5ad(self.adatapath, backed=True)\n",
    "\n",
    "    def load_whole(self):\n",
    "        self.adata = ad.read_h5ad(self.adatapath, backed=False)\n",
    "\n",
    "    def max(self):\n",
    "        return self.adata.X.max()\n",
    "\n",
    "    def min(self):\n",
    "        return self.adata.X.min()\n",
    "\n",
    "    def mean(self):\n",
    "        return self.adata.X.mean()\n",
    "\n",
    "    def median(self):\n",
    "        return np.median(self.adata.X)\n",
    "\n",
    "    def interQuartRange(self):\n",
    "        return iqr(self.adata.X)\n",
    "\n",
    "    def num_values(self):\n",
    "        return self.adata.X.shape[0] * self.adata.X.shape[1]\n",
    "\n",
    "    def sparsity_stats(self):\n",
    "        num_non_zero = 0\n",
    "        # Get the number of non-zero values\n",
    "        if issparse(self.adata.X):\n",
    "            num_non_zero = self.adata.X.nnz\n",
    "        else:\n",
    "            num_non_zero = (self.adata.X.round() != 0).sum()\n",
    "            \n",
    "        num_vals = self.num_values(self.adata)\n",
    "        num_zeros = num_vals - num_non_zero\n",
    "        sparsity = num_zeros / num_vals\n",
    "        \n",
    "        return num_zeros, num_non_zero, sparsity\n",
    "\n",
    "    def size_disk_bytes(self):\n",
    "        return get_disk_size(self.adatapath)\n",
    "    def size_adata_bytes(self): \n",
    "        return sys.getsizeof(self.adata)\n",
    "    def size_adata_backed_bytes(self): \n",
    "        return sys.getsizeof(self.adata_backed)\n",
    "\n",
    "    def random_rows_whole(self, random_samples = 10_000):\n",
    "        L = self.adata.X.shape[0]     \n",
    "        rIdx = np.sort(np.random.choice(L, size=(random_samples,), replace=True))\n",
    "        x = self.adata[rIdx, :].X\n",
    "        return x\n",
    "    def random_rows_backed(self, random_samples = 10_000):\n",
    "        L = self.adata_backed.X.shape[0]     \n",
    "        rIdx = np.sort(np.random.choice(L, size=(random_samples,), replace=True))\n",
    "        x = self.adata[rIdx, :].X\n",
    "        return x\n",
    "    def random_values_whole(self, random_samples = 10_000):\n",
    "        rows = self.adata.X.shape[0]\n",
    "        cols = self.adata.X.shape[1]\n",
    "        rIdx = np.sort(np.random.choice(rows, size=(random_samples), replace=True))\n",
    "        cIdx = np.sort(np.random.choice(cols, size=(random_samples), replace=True))\n",
    "        return [self.adata.X[r,c] for r,c in zip(rIdx, cIdx)]\n",
    "    \n",
    "    def random_values_backed(self, random_samples = 10_000):\n",
    "        rows = self.adata.X.shape[0]\n",
    "        cols = self.adata.X.shape[0]\n",
    "        rIdx = np.sort(np.random.choice(rows, size=(random_samples), replace=True))\n",
    "        cIdx = np.sort(np.random.choice(cols, size=(random_samples), replace=True))\n",
    "        return [self.adata_backed.X[r,c] for r,c in zip(rIdx, cIdx)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_all_methods\n",
    "class SCDLMetrics:\n",
    "    def __init__(self, adatapath, memmap_dir):\n",
    "        self.adatapath = adatapath\n",
    "        self.memmap_dir = memmap_dir\n",
    "    \n",
    "    def create_from_adata(self):\n",
    "        self.first_ds = SingleCellMemMapDataset(self.memmap_dir, self.adatapath)\n",
    "    def save(self):\n",
    "        self.first_ds.save()\n",
    "    def load_backed(self):\n",
    "        self.ds = SingleCellMemMapDataset(self.memmap_dir)\n",
    "    def max(self):\n",
    "        return np.max(self.ds.data)\n",
    "\n",
    "    def min(self):\n",
    "        return np.min(self.ds.data)\n",
    "\n",
    "    def mean(self):\n",
    "        return np.mean(self.ds.data)\n",
    "\n",
    "    def median(self):\n",
    "        return np.median(self.ds.data)\n",
    "\n",
    "    def interQuartRange(self):\n",
    "        return iqr(self.ds.data)\n",
    "\n",
    "    def num_values(self):\n",
    "        return self.ds.number_of_values()\n",
    "\n",
    "    def sparsity_stats(self):\n",
    "        return self.ds.sparsity()\n",
    "    \n",
    "    \n",
    "    def size_disk_bytes(self):\n",
    "        return get_disk_size(self.memmap_dir)\n",
    "    def size_mem_dataset_bytes(self): \n",
    "        return sys.getsizeof(self.ds)\n",
    "\n",
    "    def random_rows(self, random_samples = 10_000):\n",
    "        L = self.ds.number_of_rows()   \n",
    "        rIdx = np.sort(np.random.choice(L, size=(random_samples), replace=True))\n",
    "        return [self.ds[v] for v in rIdx]\n",
    "    \n",
    "    def random_values(self, random_samples = 10_000):\n",
    "        rows = self.ds.number_of_rows() \n",
    "        cols = self.ds.shape()[1][0]  \n",
    "        rIdx = np.sort(np.random.choice(rows, size=(random_samples), replace=True))\n",
    "        cIdx = np.sort(np.random.choice(cols, size=(random_samples), replace=True))\n",
    "        return [self.ds.get_row_column(r,c) for r,c in zip(rIdx, cIdx)]\n",
    "\n",
    "    def iterate_dl(self, batch_size = 8):\n",
    "        model = lambda x : x\n",
    "\n",
    "        dataloader = DataLoader(self.ds, batch_size=batch_size, shuffle=True, collate_fn=collate_sparse_matrix_batch)\n",
    "        n_epochs = 1\n",
    "        for e in range(n_epochs):\n",
    "            for batch in dataloader:\n",
    "                model(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method __init__ took 0.0000 seconds\n",
      "Method load_backed took 1.0470 seconds\n",
      "Method load_whole took 38.1525 seconds\n",
      "Method max took 0.3304 seconds\n",
      "Method min took 0.1310 seconds\n",
      "Method mean took 4.8601 seconds\n",
      "Method size_disk_bytes took 0.0031 seconds\n",
      "Disk size: 5768.38676071167 MB\n",
      "Method size_adata_bytes took 0.0639 seconds\n",
      "Adata size: 5795.636876106262 MB\n",
      "Method size_adata_backed_bytes took 0.0612 seconds\n",
      "Adata size backed: 207.6631441116333 MB\n"
     ]
    }
   ],
   "source": [
    "anndatapath = \"examples/hdf5s/9da4d19f-f6ac-4bf0-a47e-2935b1164569.h5ad\"\n",
    "anndata_m = AnnDataMetrics(anndatapath)\n",
    "anndata_m.load_backed()\n",
    "anndata_m.load_whole()\n",
    "anndata_m.max()\n",
    "anndata_m.min()\n",
    "anndata_m.mean()\n",
    "print(f\"Disk size: {anndata_m.size_disk_bytes()/(1_024**2)} MB\")\n",
    "print(f\"Adata size: {anndata_m.size_adata_bytes()/(1_024**2)} MB\")\n",
    "print(f\"Adata size backed: {anndata_m.size_adata_backed_bytes()/(1_024**2)} MB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732248790\n",
      "(356213, 18024)\n",
      "732248790\n",
      "732248790\n",
      "356214\n"
     ]
    }
   ],
   "source": [
    "#print(len(anndata_m.adata.obs))\n",
    "print(anndata_m.adata.X.nnz)\n",
    "print(anndata_m.adata.X.shape)\n",
    "print(len(anndata_m.adata.X.data))\n",
    "print(len(anndata_m.adata.X.indices))\n",
    "print(len(anndata_m.adata.X.indptr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method random_rows_whole took 0.0996 seconds\n",
      "Method random_rows_backed took 0.0642 seconds\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float32'\n",
      "\twith 20490362 stored elements and shape (10000, 18024)>\n",
      "  Coords\tValues\n",
      "  (0, 10)\t1.2342560291290283\n",
      "  (0, 14)\t0.6766462326049805\n",
      "  (0, 20)\t0.8552476763725281\n",
      "  (0, 21)\t2.3526313304901123\n",
      "  (0, 23)\t0.5917707085609436\n",
      "  (0, 25)\t0.7402293086051941\n",
      "  (0, 43)\t3.662249803543091\n",
      "  (0, 49)\t0.9115815162658691\n",
      "  (0, 74)\t1.364393949508667\n",
      "  (0, 78)\t0.5674358606338501\n",
      "  (0, 87)\t1.489476203918457\n",
      "  (0, 90)\t2.027841329574585\n",
      "  (0, 114)\t2.5541796684265137\n",
      "  (0, 115)\t1.8312854766845703\n",
      "  (0, 128)\t1.532244086265564\n",
      "  (0, 130)\t0.5525400638580322\n",
      "  (0, 131)\t1.5425962209701538\n",
      "  (0, 139)\t3.0524656772613525\n",
      "  (0, 141)\t0.582703173160553\n",
      "  (0, 146)\t1.2656664848327637\n",
      "  (0, 159)\t0.7641072273254395\n",
      "  (0, 163)\t0.9830567836761475\n",
      "  (0, 174)\t1.135430932044983\n",
      "  (0, 183)\t1.8649704456329346\n",
      "  (0, 184)\t0.9066843390464783\n",
      "  :\t:\n",
      "  (9999, 17759)\t0.4280794560909271\n",
      "  (9999, 17764)\t2.6045854091644287\n",
      "  (9999, 17774)\t1.5326236486434937\n",
      "  (9999, 17776)\t1.0443408489227295\n",
      "  (9999, 17788)\t1.5032012462615967\n",
      "  (9999, 17791)\t2.0795652866363525\n",
      "  (9999, 17826)\t2.988152503967285\n",
      "  (9999, 17828)\t0.4390471279621124\n",
      "  (9999, 17836)\t6.8023176193237305\n",
      "  (9999, 17858)\t3.183490037918091\n",
      "  (9999, 17897)\t0.15069326758384705\n",
      "  (9999, 17920)\t1.5245983600616455\n",
      "  (9999, 17921)\t3.9470651149749756\n",
      "  (9999, 17924)\t1.1225221157073975\n",
      "  (9999, 17926)\t0.7082403302192688\n",
      "  (9999, 17928)\t1.8910548686981201\n",
      "  (9999, 17932)\t0.14228954911231995\n",
      "  (9999, 17951)\t0.8182896971702576\n",
      "  (9999, 17966)\t1.7557374238967896\n",
      "  (9999, 17973)\t10.0\n",
      "  (9999, 17976)\t1.9732441902160645\n",
      "  (9999, 17979)\t2.9087119102478027\n",
      "  (9999, 17983)\t0.4227389991283417\n",
      "  (9999, 18004)\t1.1352649927139282\n",
      "  (9999, 18009)\t0.9382839798927307\n"
     ]
    }
   ],
   "source": [
    "anndata_m.random_rows_whole()\n",
    "rows = anndata_m.random_rows_backed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anndata_m.random_values_whole(random_samples = 100)\n",
    "anndata_m.random_values_backed(random_samples = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method __init__ took 0.0000 seconds\n",
      "Method create_from_adata took 46.5701 seconds\n",
      "Method save took 0.0192 seconds\n"
     ]
    }
   ],
   "source": [
    "scdl_path = \"memmap_9da4d19f\"\n",
    "scdl_m = SCDLMetrics(memmap_dir=scdl_path, adatapath=anndatapath)\n",
    "scdl_m.create_from_adata()\n",
    "scdl_m.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method load_backed took 0.0358 seconds\n",
      "Method max took 0.2057 seconds\n",
      "Method min took 0.1164 seconds\n",
      "Method mean took 0.1368 seconds\n",
      "Method sparsity_stats took 0.0000 seconds\n",
      "Method size_disk_bytes took 0.0025 seconds\n",
      "Disk size: 5590.160111427307 MB\n",
      "Method size_mem_dataset_bytes took 0.0000 seconds\n",
      "SCDataset size: 4.57763671875e-05 MB\n",
      "Method random_rows took 1.4874 seconds\n",
      "Method random_values took 0.0510 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbinder/miniforge3/envs/newenv10/lib/python3.10/site-packages/bionemo/scdl/util/torch_dataloader_utils.py:39: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  batch_sparse_tensor = torch.sparse_csr_tensor(batch_rows, batch_cols, batch_values, size=(len(batch), max_pointer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method iterate_dl took 9.4375 seconds\n"
     ]
    }
   ],
   "source": [
    "scdl_m.load_backed()\n",
    "scdl_m.max()\n",
    "scdl_m.min()\n",
    "scdl_m.mean()\n",
    "scdl_m.sparsity_stats()\n",
    "print(f\"Disk size: {scdl_m.size_disk_bytes()/(1_024**2)} MB\")\n",
    "print(f\"SCDataset size: {scdl_m.size_mem_dataset_bytes()/(1_024**2)} MB\")\n",
    "\n",
    "\n",
    "x = scdl_m.random_rows()\n",
    "y = scdl_m.random_values(random_samples = 100)\n",
    "scdl_m.iterate_dl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 1.000e+00, 4.000e+00, 7.000e+00, 2.900e+01, 9.000e+01,\n",
       "       1.536e+03])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
