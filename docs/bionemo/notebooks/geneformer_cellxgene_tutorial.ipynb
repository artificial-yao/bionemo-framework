{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a88d40b-64de-4661-b3b0-7a4b87ba0162",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BioNeMo - Geneformer inferencing for single cell downstream tasks\n",
    "\n",
    "This tutorial showcases how to run the BioNeMo container, pre-train a geneformer model, and use it for inferencing downstream single cell tasks. At the end of this tutorial, a user will learn:\n",
    "- launching the BioNeMo container\n",
    "- Download data from czi to use for pre-training and inference.\n",
    "- Convert AnnData files into the sparse CSR memmap format used by BioNeMo\n",
    "- Kick-off pretraining with a custom single cell dataset\n",
    "- Restore the pre-trained model and perform inference with the same czi dataset.\n",
    "\n",
    "\n",
    "### Prerequisites:\n",
    "- BioNeMo Framework container is running (refer to the [Getting Started](../index.md) section)\n",
    "- Familiarity with some components of the BioNeMo framework such as the [Models](../models/megamolbart.md) and [Inferencing](../inference-grpc-fw.md)\n",
    "\n",
    "\n",
    "#### Running the BioNeMo container\n",
    "\n",
    "This example has been built by launching the container in a local machine with 2 x A6000 RTX GPUs. Refer to specific instructions for [remote and multi-node launch]\n",
    "\n",
    "Once the container is launched, navigate to http://0.0.0.0:8888, http://localhost:8888, or the IP address of the workstation/node. A JupyterLab instance should show up.\n",
    "\n",
    "#### Copy this code and input files into JupyterLab\n",
    "\n",
    "In the launched JupyterLab, run the codes in a Jupyter notebook as provided in the code cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e47327a-6549-4ff4-a32a-a32d07a1e706",
   "metadata": {},
   "source": [
    "## Getting example single cell data and setting it up for inference\n",
    "\n",
    "First, we must acquire single cell training data for inference. To do this we will install the cellxgene-census api and download a small dataset. We use the example provided by the czi api examples page to download a single h5ad file. Generally, our workflow expects a collection of h5ad files to be used for pre-training. In this case, we restrict to 100k cells from a single dataset  to keep training time and downloading time small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ca29a-ffa1-4381-83b6-cad9a7b0c4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install cellxgene-census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f579ac-0207-4e07-8f34-dac0cd955c53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Below are paths required for setting up pre-training and inference.\n",
    "tutorial_data_dir = \"/workspace/bionemo/data/singlecell_tutorial/download_anndata\"\n",
    "train_tutorial_data_dir = \"/workspace/bionemo/data/singlecell_tutorial/download_anndata/train\"\n",
    "val_tutorial_data_dir = \"/workspace/bionemo/data/singlecell_tutorial/download_anndata/val\"\n",
    "test_tutorial_data_dir = \"/workspace/bionemo/data/singlecell_tutorial/download_anndata/test\"\n",
    "\n",
    "train_tutorial_processed_dir = \"/workspace/bionemo/data/singlecell_tutorial/processed_data/train\"\n",
    "val_tutorial_processed_dir = \"/workspace/bionemo/data/singlecell_tutorial/processed_data/val\"\n",
    "test_tutorial_processed_dir = \"/workspace/bionemo/data/singlecell_tutorial/processed_data/test\"\n",
    "tutorial_output_dir = \"/workspace/bionemo/data/singlecell_tutorial/inference_output\"\n",
    "tutorial_output_inference_pickle = f\"{tutorial_output_dir}/human_covid19_bcells_from_scratch.pkl\"\n",
    "demo_data_train_download_path = f\"{train_tutorial_data_dir}/human_covid19_bcells.h5ad\"\n",
    "demo_data_val_download_path = f\"{val_tutorial_data_dir}/human_covid19_bcells.h5ad\"\n",
    "demo_data_test_download_path = f\"{test_tutorial_data_dir}/human_covid19_bcells.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88bd2844-0251-476e-9e3f-8d4e89474f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p {train_tutorial_data_dir}\n",
    "!mkdir -p {val_tutorial_data_dir}\n",
    "!mkdir -p {test_tutorial_data_dir}\n",
    "!mkdir -p {train_tutorial_processed_dir}\n",
    "!mkdir -p {val_tutorial_processed_dir}\n",
    "!mkdir -p {test_tutorial_processed_dir}\n",
    "!mkdir -p {tutorial_output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ccf03f0-1590-434e-a314-8ff0a02f5ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cellxgene_census\n",
    "frac_train = 0.8\n",
    "frac_val = 0.1\n",
    "frac_test = 0.1\n",
    "\n",
    "with cellxgene_census.open_soma(census_version=\"2023-12-15\") as census:\n",
    "    filter1 = \"cell_type == 'B cell' and tissue_general == 'lung' and disease == 'COVID-19' and is_primary_data == True\"\n",
    "\n",
    "    adata = cellxgene_census.get_anndata(\n",
    "        census = census,\n",
    "        organism = \"Homo sapiens\",\n",
    "        obs_value_filter = filter1,\n",
    "    )\n",
    "    n_train = int(adata.shape[0] * frac_train)\n",
    "    n_val = int(adata.shape[0] * frac_val)\n",
    "    n_test = adata.shape[0] - n_train - n_val\n",
    "    # Create some splits, bad practice since ordering may be a thing but let's just take ranges for this demo.\n",
    "    adata_train = adata[0:n_train].copy()\n",
    "    adata_val = adata[n_train:(n_train+n_val)].copy()\n",
    "    adata_test = adata[(n_train+n_val):].copy()\n",
    "    adata_train.write(demo_data_train_download_path)\n",
    "    adata_val.write(demo_data_val_download_path)\n",
    "    adata_test.write(demo_data_test_download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b060e73b-a3f9-4315-ae91-c23b9a29f490",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 gkaushik domain-users 22M Sep 12 10:03 /workspace/bionemo/data/singlecell_tutorial/download_anndata/train/human_covid19_bcells.h5ad\n",
      "-rw-r--r-- 1 gkaushik domain-users 12M Sep 12 10:03 /workspace/bionemo/data/singlecell_tutorial/download_anndata/val/human_covid19_bcells.h5ad\n",
      "-rw-r--r-- 1 gkaushik domain-users 13M Sep 12 10:03 /workspace/bionemo/data/singlecell_tutorial/download_anndata/test/human_covid19_bcells.h5ad\n"
     ]
    }
   ],
   "source": [
    "!ls -laht {demo_data_train_download_path}\n",
    "!ls -laht {demo_data_val_download_path}\n",
    "!ls -laht {demo_data_test_download_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1812f0e-7179-4140-aa9c-8109813f3e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create training data processed directory\n",
    "!python /workspace/bionemo/bionemo/data/singlecell/sc_memmap.py \\\n",
    "  --data-path {train_tutorial_data_dir} \\\n",
    "  --save-path {train_tutorial_processed_dir}\n",
    "\n",
    "# Create validation data processed directory\n",
    "!python /workspace/bionemo/bionemo/data/singlecell/sc_memmap.py \\\n",
    "  --data-path {val_tutorial_data_dir} \\\n",
    "  --save-path {val_tutorial_processed_dir}\n",
    "\n",
    "# Create test data processed directory\n",
    "!python /workspace/bionemo/bionemo/data/singlecell/sc_memmap.py \\\n",
    "  --data-path {test_tutorial_data_dir} \\\n",
    "  --save-path {test_tutorial_processed_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd212acb-9695-4ec4-bff6-8669693118f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 13M\n",
      "-rw-r--r-- 1 gkaushik domain-users 157K Sep 12 10:05 features.csv\n",
      "drwxr-xr-x 2 gkaushik domain-users 4.0K Sep 12 10:05 .\n",
      "-rw-r--r-- 1 gkaushik domain-users 5.9M Sep 12 10:05 gene_expression_ind.npy\n",
      "-rw-r--r-- 1 gkaushik domain-users  15K Sep 12 10:05 gene_expression_ptr.npy\n",
      "-rw-r--r-- 1 gkaushik domain-users 5.9M Sep 12 10:05 gene_expression_data.npy\n",
      "-rw-r--r-- 1 gkaushik domain-users 1.1M Sep 12 10:05 metadata.json\n",
      "drwxr-xr-x 5 gkaushik domain-users 4.0K Sep 12 10:00 ..\n",
      "total 4.5M\n",
      "-rw-r--r-- 1 gkaushik domain-users  19K Sep 12 10:06 features.csv\n",
      "drwxr-xr-x 2 gkaushik domain-users 4.0K Sep 12 10:06 .\n",
      "-rw-r--r-- 1 gkaushik domain-users 1.7M Sep 12 10:06 gene_expression_ind.npy\n",
      "-rw-r--r-- 1 gkaushik domain-users 1.9K Sep 12 10:06 gene_expression_ptr.npy\n",
      "-rw-r--r-- 1 gkaushik domain-users 1.7M Sep 12 10:06 gene_expression_data.npy\n",
      "-rw-r--r-- 1 gkaushik domain-users 1.1M Sep 12 10:06 metadata.json\n",
      "drwxr-xr-x 5 gkaushik domain-users 4.0K Sep 12 10:00 ..\n",
      "total 3.2M\n",
      "-rw-r--r-- 1 gkaushik domain-users  20K Sep 12 10:06 features.csv\n",
      "drwxr-xr-x 2 gkaushik domain-users 4.0K Sep 12 10:06 .\n",
      "-rw-r--r-- 1 gkaushik domain-users 1.1M Sep 12 10:06 gene_expression_data.npy\n",
      "-rw-r--r-- 1 gkaushik domain-users 1.1M Sep 12 10:06 gene_expression_ind.npy\n",
      "-rw-r--r-- 1 gkaushik domain-users 1.9K Sep 12 10:06 gene_expression_ptr.npy\n",
      "-rw-r--r-- 1 gkaushik domain-users 1.1M Sep 12 10:06 metadata.json\n",
      "drwxr-xr-x 5 gkaushik domain-users 4.0K Sep 12 10:00 ..\n"
     ]
    }
   ],
   "source": [
    "!ls -laht {train_tutorial_processed_dir}\n",
    "!ls -laht {test_tutorial_processed_dir}\n",
    "!ls -laht {val_tutorial_processed_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43efdd-8ba5-4a3b-8f70-9b5839ec075c",
   "metadata": {},
   "source": [
    "# Pretraining\n",
    "Now that we have aquired the h5ad files we would like to use for training and converted them to a sparse memmap. We will kickoff training. This involves two distinct steps\n",
    "- preprocessing (indicated with do_training=False), where artifacts are downloaded from huggingface to be used by the model. Importantly, we set the `dataset_path` to be the same place we created the sparse memmap files. This is how BioNeMo knows where to find files for training, including both training data and additional artifacts (such as tokenizers).\n",
    "- pretraining, where the model is actually trained.\n",
    "\n",
    "We set the flag `max_steps` to limit the runtime. Check the full config file in `examples/singlecell/geneformer/conf` for a complete list of arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424247a7-105b-4bea-b34e-b28a8f5787af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run preprocessing to acquire the requisite files for pre-training.\n",
    "!python /workspace/bionemo/examples/singlecell/geneformer/pretrain.py \\\n",
    "  ++model.data.train_dataset_path={train_tutorial_processed_dir} \\\n",
    "  ++model.data.val_dataset_path={val_tutorial_processed_dir} \\\n",
    "  ++model.data.test_dataset_path={test_tutorial_processed_dir} \\\n",
    "  ++do_training=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aeeb46-3733-44b8-ba90-e8fd127d7441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pretrain the model using\n",
    "!python /workspace/bionemo/examples/singlecell/geneformer/pretrain.py \\\n",
    "  --config-dir /workspace/bionemo/examples/singlecell/geneformer/conf \\\n",
    "  --config-name geneformer_config \\\n",
    "  ++model.data.train_dataset_path={train_tutorial_processed_dir} \\\n",
    "  ++model.data.val_dataset_path={val_tutorial_processed_dir} \\\n",
    "  ++model.data.test_dataset_path={test_tutorial_processed_dir} \\\n",
    "  ++trainer.devices=1 \\\n",
    "  ++trainer.max_steps=200 \\\n",
    "  ++exp_manager.exp_dir={tutorial_output_dir} \\\n",
    "  ++exp_manager.wandb_logger_kwargs.project=\"geneformer_pretrain_test\" \\\n",
    "  ++model.data.output_fname={tutorial_output_inference_pickle} \\\n",
    "  ++exp_manager.wandb_logger_kwargs.offline=True \\\n",
    "  ++exp_manager.resume_if_exists=False \\\n",
    "  ++do_training=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23771e9-0dd6-414e-8cd0-5cd9a9dd4a6b",
   "metadata": {},
   "source": [
    "# Running inference.\n",
    "\n",
    "We can see from the above training job that the model was trained for a short number of steps. Note the end of the log file the experiment manager leaves a message about where the resulting `.nemo` file is written. This file is used for finetuning, inference, or training from an existing set of model weights. See the example produced below from our run:\n",
    "\n",
    "```text\n",
    "[NeMo I 2024-04-26 22:02:36 nemo_model_checkpoint:183] New .nemo model saved to: /workspace/bionemo/data/singlecell_tutorial/inference_output/geneformer/2024-05-13_16-33-16/checkpoints/geneformer.nemo\n",
    "[NeMo I 2024-04-26 22:02:36 nlp_overrides:412] Removing checkpoint: /workspace/bionemo/data/singlecell_tutorial/inference_output/geneformer/2024-05-13_16-33-16/checkpoints/geneformer--val_loss=8.70-step=100-consumed_samples=800.0-last.ckpt\n",
    "Epoch 0: 100%|█| 200/200 [00:27<00:00,  7.17it/s, v_num=2-05, reduced_train_loss`Trainer.fit` stopped: `max_steps=200` reached.\n",
    "Epoch 0: 100%|█| 200/200 [00:27<00:00,  7.17it/s, v_num=2-05, reduced_train_loss\n",
    "```\n",
    "\n",
    "We will take the `.nemo` file logged:\n",
    "`/workspace/bionemo/data/singlecell_tutorial/inference_output/geneformer/2024-04-26_22-02-05/checkpoints/geneformer.nemo`\n",
    "\n",
    "and use this for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b11a330-b8f6-491a-b608-fe47e78f83ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/bionemo/data/singlecell_tutorial/inference_output/geneformer/2024-09-12_10-07-12/checkpoints/geneformer.nemo\n"
     ]
    }
   ],
   "source": [
    "# Find latest checkpoint file\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "directory = '/workspace/bionemo/data/singlecell_tutorial/inference_output/geneformer'\n",
    "timestamped_dirs = []\n",
    "\n",
    "for dir_name in os.listdir(directory):\n",
    "    dir_path = os.path.join(directory, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        try:\n",
    "            timestamp = datetime.strptime(dir_name, \"%Y-%m-%d_%H-%M-%S\")\n",
    "            timestamped_dirs.append((dir_name, timestamp))\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "latest_dir = max(timestamped_dirs, key=lambda x: x[1])\n",
    "pretrained_nemo_file = f'/workspace/bionemo/data/singlecell_tutorial/inference_output/geneformer/{latest_dir[0]}/checkpoints/geneformer.nemo'\n",
    "print(pretrained_nemo_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a327d-a5b1-49c9-96b3-141ae99baeb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run inference on test\n",
    "!python /workspace/bionemo/bionemo/model/infer.py \\\n",
    "  --config-dir /workspace/bionemo/examples/singlecell/geneformer/conf \\\n",
    "  --config-name infer \\\n",
    "  ++model.downstream_task.restore_from_path={pretrained_nemo_file} \\\n",
    "  ++model.data.dataset_path={test_tutorial_processed_dir} \\\n",
    "  ++exp_manager.exp_dir={tutorial_output_dir} \\\n",
    "  ++model.data.output_fname={tutorial_output_inference_pickle} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9a425-850d-4027-9160-5e659c163604",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load inference result and cluster with UMAP.\n",
    "Now we will inspect our result. First, we expect there to be one prediction for each cell, we can compare the shape of the anndata object to the predictions produced by our model. After this, we can simply pass our embeddings into umap, and view the result! In this case its a very poorly trained model with very few cells, so keep expectations low!\n",
    "\n",
    "The inference_results pickle file contains one set of hiddens and embeddings for each cell. The hiddens contain the embedding per-token, whereas the embeddings contain the mean embedding for all gene tokens with special tokens (CLS, MASK, etc) removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2895e979-1652-49f2-96e9-b63b66191ada",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, (2313, 60664), dict_keys(['embeddings']))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(tutorial_output_inference_pickle, 'rb') as inference_handle:\n",
    "    inference_results = pickle.load(inference_handle)\n",
    "len(inference_results), adata.shape, inference_results[0].keys()\n",
    "#NBVAL_CHECK_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "621decfb-2fd1-44dd-86e5-69e7ddcb8235",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_results[0]['embeddings'].shape\n",
    "#NBVAL_CHECK_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d80061f4-3311-4246-9640-177d4ca3b9a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform([x['embeddings'] for x in inference_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "704d37ad-ac98-4868-9249-bd2ada17a8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape\n",
    "#NBVAL_CHECK_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb625795-627c-4694-ac8e-652a4d291a7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert adata_test.obs.shape[0] == len(inference_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea88b8a-bb3c-4058-93a0-9afb0dfedfa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "results = adata_test.obs.copy()\n",
    "results['x'] = embedding[:, 0]\n",
    "results['y'] = embedding[:, 1]\n",
    "\n",
    "covariates = [\"assay\", \"development_stage\", \"dataset_id\", \"sex\"]\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(10,10))\n",
    "\n",
    "for ax,covar in zip(axes.flat, covariates):\n",
    "    for cov, cov_df in results.groupby(covar):\n",
    "        ax.scatter(\n",
    "            cov_df.x,\n",
    "            cov_df.y,\n",
    "            s=3,\n",
    "            alpha=0.75,\n",
    "            label=cov,\n",
    "        )\n",
    "    if len(results[covar].unique()) < 8:\n",
    "        ax.legend()\n",
    "    ax.set_title(f\"Embeddings by {covar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb8266-7451-495b-bdae-9bd51c6a214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_test.obs.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
